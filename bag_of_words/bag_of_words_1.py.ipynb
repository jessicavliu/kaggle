{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup \n",
    "import re\n",
    "import nltk\n",
    "#nltk.download()\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper\n",
    "def clean_review(raw_review, porter_stem = False):\n",
    "    #remove html <- BeautifulSoup\n",
    "    review_text = BeautifulSoup(raw_review).get_text()\n",
    "    \n",
    "    #remove bad chars (non-letters in this case) <- re\n",
    "    #convert to lowercase and split into words <- re\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", review_text)\n",
    "    words = letters_only.lower().split()\n",
    "    \n",
    "    #remove stopwords and apply Porter Stemmer <- nltk\n",
    "    #Porter Stemmer maps verbs with same roots of various endings \n",
    "    \n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    good_words = [w for w in words if w not in stops]\n",
    "    \n",
    "    if porter_stem:\n",
    "        ps = PorterStemmer()\n",
    "        good_words = [ps.stem(w) for w in good_words]\n",
    "\n",
    "    good_text = \" \".join(good_words)\n",
    "    \n",
    "    return good_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train model using training set\n",
    "def train(porter_stem = False):\n",
    "    #read file\n",
    "    train = pd.read_csv(\"labeledTrainData.tsv\", header=0, delimiter = \"\\t\", quoting=3)\n",
    "    \n",
    "    num_reviews = train['review'].size\n",
    "    clean_train_reviews = []\n",
    "    \n",
    "    #clean all reviews\n",
    "    for i in range(num_reviews):\n",
    "        if i % 5000 == 0:\n",
    "            print(\"processing review\", i, \"/\", num_reviews)\n",
    "        clean_train_reviews.append(clean_review(train['review'][i], porter_stem))\n",
    "    \n",
    "    #train model and apply to clean_reviews\n",
    "    vectorizer = CountVectorizer(analyzer = \"word\",   \\\n",
    "                                 tokenizer = None,    \\\n",
    "                                 preprocessor = None, \\\n",
    "                                 stop_words = None,   \\\n",
    "                                 max_features = 5000) \n",
    "\n",
    "    print(\"finding features...\")\n",
    "    train_data_features = vectorizer.fit_transform(clean_train_reviews)\n",
    "    \n",
    "    #convert to np array - each review has 5000 features. The nth column is a count of the nth most frequent word\n",
    "    train_data_features = train_data_features.toarray()\n",
    "\n",
    "    #init random forest of 100 trees\n",
    "    forest = RandomForestClassifier(n_estimators = 100) \n",
    "\n",
    "    #train forest on training set\n",
    "    print(\"training forest...\")\n",
    "    forest = forest.fit(train_data_features, train[\"sentiment\"] )\n",
    "    \n",
    "    print(\"done\")\n",
    "    \n",
    "    return vectorizer, forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing review 0 / 25000\n",
      "processing review 5000 / 25000\n",
      "processing review 10000 / 25000\n",
      "processing review 15000 / 25000\n",
      "processing review 20000 / 25000\n",
      "finding features...\n",
      "training forest...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "porter_stem = False\n",
    "vectorizer, forest = train(porter_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying model to test data\n",
    "\n",
    "#read test data\n",
    "test = pd.read_csv(\"testData.tsv\", header=0, delimiter=\"\\t\", \\\n",
    "                       quoting=3 )\n",
    "\n",
    "def test_fn(porter_stem = False):  \n",
    "    num_reviews = len(test[\"review\"])\n",
    "    clean_test_reviews = [] \n",
    "    \n",
    "    #clean reviews\n",
    "    for i in range(num_reviews):\n",
    "        if i % 5000 == 0:\n",
    "            print(\"processing review\", i, \"/\", num_reviews)\n",
    "        clean_test_reviews.append(clean_review(test['review'][i], porter_stem))\n",
    "    \n",
    "    #transform into 5000-len vectors (but don't fit, because we don't want to re-find the most frequent words)\n",
    "    test_data_features = vectorizer.transform(clean_test_reviews)\n",
    "    test_data_features = test_data_features.toarray()\n",
    "\n",
    "    # Use the random forest to make sentiment label predictions\n",
    "    result = forest.predict(test_data_features)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing review 0 / 25000\n",
      "processing review 5000 / 25000\n",
      "processing review 10000 / 25000\n",
      "processing review 15000 / 25000\n",
      "processing review 20000 / 25000\n"
     ]
    }
   ],
   "source": [
    "result = test_fn(porter_stem)\n",
    "\n",
    "# Copy the results to a pandas dataframe with an \"id\" column and a \"sentiment\" column\n",
    "output = pd.DataFrame( data={\"id\":test[\"id\"], \"sentiment\":result} )\n",
    "\n",
    "# Use pandas to write the comma-separated output file\n",
    "\n",
    "if porter_stem:\n",
    "    output.to_csv( \"Bag_of_Words_Porter_model.csv\", index=False, quoting=3 )\n",
    "else:\n",
    "    output.to_csv( \"Bag_of_Words_model.csv\", index=False, quoting=3 )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
